{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the main folder containing subfolders for each class in your Google Drive\n",
        "data_directory = '/content/drive/MyDrive/DATAI/Class_Samples'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0AEz6La5AUL",
        "outputId": "0f1ec747-67b7-4a65-9dfd-aeb593c0e188"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIO_Z-1t3zRW",
        "outputId": "bb399933-97ed-46ee-a9ab-28cdb8e9d4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 260 images belonging to 3 classes.\n",
            "Found 64 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 108s 10s/step - loss: 1.5782 - accuracy: 0.3846 - val_loss: 1.0961 - val_accuracy: 0.3281\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 1.0764 - accuracy: 0.4269 - val_loss: 1.0325 - val_accuracy: 0.6406\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.9367 - accuracy: 0.5692 - val_loss: 0.7369 - val_accuracy: 0.9531\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.5616 - accuracy: 0.7731 - val_loss: 0.2600 - val_accuracy: 0.9844\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.2697 - accuracy: 0.9077 - val_loss: 0.1411 - val_accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.1322 - accuracy: 0.9577 - val_loss: 0.1074 - val_accuracy: 0.9531\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.1387 - accuracy: 0.9577 - val_loss: 0.0511 - val_accuracy: 0.9844\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.0985 - accuracy: 0.9615 - val_loss: 0.0571 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.0577 - accuracy: 0.9808 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.0029 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f373ffae2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Set the image dimensions and batch size\n",
        "image_width, image_height = 128, 128\n",
        "batch_size = 32\n",
        "\n",
        "# Create separate ImageDataGenerator objects for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,  # Normalize pixel values to [0, 1]\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Splitting 20% of the data as validation set\n",
        ")\n",
        "\n",
        "# Generate training data from the images in the subfolders\n",
        "train_data_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_directory,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training'  # Subset of the data for training\n",
        ")\n",
        "\n",
        "# Generate validation data from the images in the subfolders\n",
        "validation_data_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_directory,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation'  # Subset of the data for validation\n",
        ")\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(train_data_generator.class_indices)\n",
        "\n",
        "# Define the CNN model with dropout layers\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Dropout layer with dropout rate of 0.25\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Dropout layer with dropout rate of 0.25\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Dropout layer with dropout rate of 0.25\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 0.5\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with validation\n",
        "model.fit(\n",
        "    train_data_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_data_generator\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/DATAI/trained_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY3PBlNE31tY",
        "outputId": "77859455-006a-4b95-b5b2-8886e98404d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3W1nxqnk3-RD"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}